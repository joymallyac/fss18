<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Stats - Found.Soft.Sci</title>
        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
        <link href="../../css/extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="../..">Found.Soft.Sci</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="../..">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Notes <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">Admin</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../syllabus/">Syllabus &#10004;</a>
</li>
            
<li >
    <a href="http://tiny.cc/fss18give">Submit site &#10004;</a>
</li>
            
<li >
    <a href="http://found18.slack.com">Chat &#10004;</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Starting</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../inspiration/">Inspiration &#10004;</a>
</li>
            
<li >
    <a href="../../history/">SE+AI,  then and now &#10004;</a>
</li>
            
<li >
    <a href="../baselines/">Baselines for Adequate AI &#10004;</a>
</li>
            
<li >
    <a href="../simple/">Simplicity ;</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Lectures</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../eval">Eval &#10004</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#">Stats</a>
    <ul class="dropdown-menu">
            
<li >
    <a href=".">Stats lecture   &#10004</a>
</li>
            
<li >
    <a href="http://menzies.us/lean/knn.html">Stats example   &#10004</a>
</li>
    </ul>
  </li>
            
<li >
    <a href="../domination">Domination &#10004</a>
</li>
            
<li >
    <a href="../tables/">Tables and Ranges &#10004</a>
</li>
            
<li >
    <a href="../dt101/">Decision trees 101 &#10004</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">H/W <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../proj/ProjectIdeas">Project Ideas</a>
</li>
                                    
<li >
    <a href="../../proj/w78/">Seven, Eight &#10004;</a>
</li>
                                    
<li >
    <a href="../../proj/w6/">Six &#10004;</a>
</li>
                                    
<li >
    <a href="../../proj/w5/">Five &#10004;</a>
</li>
                                    
<li >
    <a href="../../proj/w4/">Four &#10004;</a>
</li>
                                    
<li >
    <a href="../../proj/w3/">Three &#10004;</a>
</li>
                                    
<li >
    <a href="../../proj/w1/">One &#10004;</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Review</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../review/three">Week 3</a>
</li>
            
<li >
    <a href="../../review/two">Week 2 &#10004;</a>
</li>
            
<li >
    <a href="../../review/one">Week 1 &#10004;</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">A-Z <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">A</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../axe/">Axe</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">D</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../deeplearning/">Deep learning &#10004;</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">E</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../effectsize.md">Effect size</a>
</li>
            
<li >
    <a href="../explain/">Explanation</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">B</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../bootstrap.md">Bootstrap</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">S</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../significance.md">Significance test</a>
</li>
            
<li >
    <a href="../sk.md">Scott-Knot</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">T</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../tables/">Tables</a>
</li>
            
<li >
    <a href="../things.md">Things</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#">Tools</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#">Data mining</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../aa">Matlab</a>
</li>
            
<li >
    <a href="../../bb">R</a>
</li>
            
<li >
    <a href="../../cc">Weka</a>
</li>
            
<li >
    <a href="../../dd">scikit-learn</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">Optimizers</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../dd">JMetal</a>
</li>
            
<li >
    <a href="../../dd">Deep</a>
</li>
            
<li >
    <a href="../../ee">EvoSuite</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li >
                                <a href="../../license/">(c) 2018</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#stats">Stats</a></li>
        <li class="main "><a href="#comparing-treatments">Comparing Treatments</a></li>
            <li><a href="#how-to-comapre-results">How to Comapre Results</a></li>
            <li><a href="#percentile-charts">Percentile Charts</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="stats">Stats</h1>
<h1 id="comparing-treatments">Comparing Treatments</h1>
<p>Your task:</p>
<ol>
<li>Download<ul>
<li><a href="https://github.com/txt/ase16/blob/master/src/stats0.txt">stats0.txt</a></li>
<li><a href="https://github.com/txt/ase16/blob/master/src/stat2.txt">stat2.txt</a></li>
<li><a href="https://gist.github.com/Suvodeep90/16bd4cb8aa82c10e359a2ad5e54ed4f8">stats.py</a></li>
</ul>
</li>
<li>Repeat  the following exercise for <code>stat2.txt</code>, then <code>stats0.txt</code><ul>
<li>Look at the data in stats0.txt;</li>
<li>Sort them by their median;</li>
<li>Draw percentile charts for each (no need to be super accurate, near enough is good enough);</li>
<li>Do any of these seven groups cluster together?</li>
<li>When you have answers to all the above (and not before), compare your results to
     <code>cat statX.txt | python stats.py --text 30</code></li>
</ul>
</li>
<li>Run
   <code>python stat4.py | python stats.py</code>  and comment if you
   agree or disagree with the output.</li>
</ol>
<h2 id="how-to-comapre-results">How to Comapre Results</h2>
<p>To compare  if treatment 1 is better than another, apply the followng rules:</p>
<ol>
<li>Visualize the data, somehow.</li>
<li>Check if the central tendency of one distribution is <em>better</em> than
    the other; e.g. compare their median values.</li>
<li>Check the different between the central tendencies is not some
    <em>small effect</em>.</li>
<li>Check if the distributions are <em>significantly different</em>;</li>
</ol>
<p>That is:</p>
<p>When faced with new data, always chant the following mantra:</p>
<ul>
<li><em>First</em> visualize it to get some intuitions;</li>
<li><em>Then</em> apply some statistics to double check those intuitions.</li>
</ul>
<p>That is, it is <em>strong recommended</em> that, prior doing any statistical
work, an analyst generates a visualization of the data.</p>
<p>(And some even say, do not do stats at all:</p>
<ul>
<li>"If you need statistics, you did the wrong experiment." -- Enrest Rutherford.)</li>
</ul>
<p>Sometimes, visualizations are enough:</p>
<ul>
<li><a href="https://www.cs.uic.edu/~tdang/file/CHIRP-KDD.pdf">CHIRP: A new classifier based on
Composite Hypercubes on Iterated Random Projections</a></li>
<li><a href="https://github.com/ds4se/chapters/blob/master/turhanb/theGraph.md">Simpler Questions Can Lead To Better Insights</a>, from
  Perspectives on Data Science for Software Engineering, Morgan-Kaufmann, 2015</li>
</ul>
<h2 id="percentile-charts">Percentile Charts</h2>
<p>Percentile
charts a simple way to display very large populations in very little
space.
The advantage of percentile charts is that we can show a lot of data in
very little space.</p>
<p>For example, here's an example where the <em>xtile</em> Python function
shows 2000 numbers on two lines:</p>
<p>Consider two distributions, of 1000 samples each: one shows square root
of a <em>rand()</em> and the other shows the square of a <em>rand()</em>.</p>
<pre><code>    10:       def _tile() :
    11:         import random
    12:         r = random.random
    13:         def show(lst):
    14:           return xtile(lst,lo=0, hi=1,width=25,
    15:                        show= lambda s:" %3.2f" % s)
    16:         print "one", show([r()*0.5 for x in range(1000)])
    17:         print "two", show([r()*2   for x in range(1000)])
</code></pre>
<p>In the following quintile charts, we show these distributions:</p>
<ul>
<li>The range is 0 to 1.</li>
<li>One line shows the square of 1000 random numbers;</li>
<li>The other line shows the square root of 1000 random numbers;</li>
</ul>
<p>Note the brevity of the display:</p>
<pre><code> one        -----|    *  ---  , 0.32,  0.55,  0.70,  0.84,  0.95
 two --    *     |--------    , 0.01,  0.10,  0.27,  0.51,  0.85
</code></pre>
<ul>
<li>Quintiles divide the data into the 10th, 30th, 50th, 70th, 90th
    percentile.</li>
<li>Dashes (<em>"-"</em>) mark the range (10,30)th and (70,90)th percentiles;</li>
<li>White space marks the ranges (30,50)th and (50,70)th percentiles.</li>
<li>The vertical bar <em>"|"</em> shows half way between the display's
min and max .</li>
</ul>
<p>BTW, there are <a href="http://www.tableau.com/about/blog/2013/7/list-books-about-data-visualisation-24182"><em>many</em> more ways to view results</a> than just percentiles</p>
<h3 id="medians">Medians</h3>
<p>To compare  if one optimizer is better than another, apply the followng rules:</p>
<ol>
<li>Visualize the data, somehow.</li>
<li><b>Check if the central tendency of one distribution is <em>better</em> than
    the other; e.g. compare their median values.</b></li>
<li>Check the different between the central tendencies is not some
    <em>small effect</em>.</li>
<li>Check if the distributions are <em>significantly different</em>;</li>
</ol>
<p>All things considered,
means do not mean much, especially for highly skewed distributions.
For example:</p>
<ul>
<li>Bill Gates and 35 homeless people are in the same room.</li>
<li>Their mean annual income is over a billion dollars each- which is
  a number that characterized neither Mr. Gates or the homeless people.</li>
<li>On the other hand, the median income of that population is close to zero-
  which is a number that characterizes most of that population.</li>
</ul>
<p>The median of a list is the middle item of the sorted values, if the list is of an odd size.
If the list size is even, the median is the two values either side of the middle:</p>
<pre><code>def median(lst,ordered=False):
   lst = lst if ordered else sorted(lst)
   n   = len(lst)
   p   = n // 2
   if (n % 2):  return lst[p]
   p,q = p-1,p
   q   = max(0,(min(q,n)))
   return (lst[p] + lst[q]) * 0.5
</code></pre>
<h3 id="check-for-small-effects">Check for "Small Effects"</h3>
<p>To compare  if one optimizer is better than another, apply the followng rules:</p>
<ol>
<li>Visualize the data, somehow.</li>
<li>Check if the central tendency of one distribution is <em>better</em> than
    the other; e.g. compare their median values.</li>
<li><b>Check the different between the central tendencies is not some
    <em>small effect</em>.</b></li>
<li>Check if the distributions are <em>significantly different</em>;</li>
</ol>
<p>An <em>effect size</em> test is a sanity check that can be summarizes as follows:</p>
<ul>
<li>Don't  sweat the small stuff;</li>
</ul>
<p>I.e. ignore small differences between items in the samples.</p>
<p>There parametric and non-parametric tests for "small effects" (which, if we find, we should just ignore).</p>
<p>Parametric tests assume that the numbers fit some simple distribution (e.g. the normal Gaussian curve).</p>
<h4 id="cohens-rule">Cohen's rule:</h4>
<ul>
<li>compare means <em>&Delta; = &mu;1-&mu;2</em> between two samples;</li>
<li>compute the standard deviation &sigma; of the combined samples;</li>
<li>large effect if &Delta; &lt; 0.5*&sigma;</li>
<li>medium effect if &Delta; &lt; 0.3*&sigma;</li>
<li>small effect if &Delta; &lt; 0.1*&sigma;; And "small effect" means "yawn", too small to be interesting.</li>
</ul>
<p>Widely viewed as too simplistic.</p>
<h4 id="hedges-rule-using-g">Hedge's rule (using <em>g</em>):</h4>
<ul>
<li>Still parametric</li>
<li>Modifies &Delta; w.r.t. the standard deviation of both samples.</li>
<li>Adds a correction factor <em>c</em> for small sample sizes.</li>
<li>In their review of use of effect size in SE, Kampenses et al. report that many papers use something like <em>g &lt; 0.38</em>
  is the boundary between <em>small effects</em> and bigger effects.
        - <a href="https://pdfs.semanticscholar.org/e6be/263f60ccfb294e14422f0e0162b1367063a2.pdf"> Systematic Review of Effect Size in
Software Engineering Experiments </a>
          Kampenes, Vigdis By, et al.  Information and Software Technology 49.11 (2007): 1073-1086.
        - See equations 2,3,4 and Figure 9</li>
</ul>
<pre><code class="python">def hedges(i,j,small=0.38):
    &quot;&quot;&quot;
    Hedges effect size test.
    Returns true if the &quot;i&quot; and &quot;j&quot; difference is only a small effect.
    &quot;i&quot; and &quot;j&quot; are   objects reporing mean (i.mu), standard deviation (i.s)
    and size (i.n) of two  population of numbers.
    &quot;&quot;&quot;
    num   = (i.n - 1)*i.s**2 + (j.n - 1)*j.s**2
    denom = (i.n - 1) + (j.n - 1)
    sp    = ( num / denom )**0.5
    delta = abs(i.mu - j.mu) / sp
    c     = 1 - 3.0 / (4*(i.n + j.n - 2) - 1)
    return delta * c &lt; small
</code></pre>

<p><a href="https://gist.github.com/timm/33578871be53e604da83679dc7ccbcc5">Code</a></p>
<h4 id="cliffs-delta">Cliff's Delta</h4>
<p>non-parametric</p>
<p>Cliff's delta counts <em>bigger</em> and <em>smaller</em>.</p>
<pre><code class="python">def cliffsDelta(lst1, lst2, small=0.147): # assumes all samples are nums
    &quot;Cliff's delta between two list of numbers i,j.&quot;
    lt = gt = 0
    for x in lst1:
      for y in lst2 :
        if x &gt; y: gt += 1
        if x &lt; y: lt += 1
    z = abs(lt - gt) / (len(lst1) * len(lst2))
    return z &lt; small # true is small effect in difference
</code></pre>

<p>As above, could be optimized with a <a href="http://menzies.us/lean/stats.html">pre-sort</a>.</p>
<h3 id="statistically-significantly-different">Statistically Significantly Different</h3>
<p>To compare  if one optimizer is better than another, apply the followng rules:</p>
<ol>
<li>Visualize the data, somehow.</li>
<li>Check if the central tendency of one distribution is <em>better</em> than
    the other; e.g. compare their median values.</li>
<li>Check the different between the central tendencies is not some
    <em>small effect</em>.</li>
<li><b>Check if the distributions are <em>significantly different</em>;</b></li>
</ol>
<p>In any experiment or observation that involves drawing a sample from a
population, there is always the possibility that an observed effect would have
occurred due to sampling error alone.</p>
<p>A <em>significance</em> test checks that the observed effect is not due to noise, to
degree of certainty "c".</p>
<p>Note that the term <em>significance</em> does not imply <em>importance</em> and the term
statistical significance is not the same as research, theoretical, or practical
significance. For example:</p>
<ul>
<li>Code can be developed by local teams or distributed teams spread
  around the world.</li>
<li>It turns out the bug rate of these two methods is
  statistically significantly different.</li>
<li>But the size of the different is about zero (as detected by the Hedge's test,
  shown below).</li>
<li>From Ekrem Kocaguneli, Thomas Zimmermann, Christian Bird, Nachiappan Nagappan, and Tim
  Menzies. 2013. Distributed development considered harmful?. In Proceedings of the 2013
  International Conference on Software Engineering (ICSE '13). IEEE Press, Piscataway,
  NJ, USA, 882-890.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/txt/ase16/master/img/bugs.png"></p>
<p>For these reasons, standard statistical tests are coming under fire:</p>
<ul>
<li>Various high profile journals are banning the use  the
  null hypothesis significance testing procedure (NHSTP) (a classic statistical
  significance test) from their articles <a href="https://www.r-bloggers.com/why-the-ban-on-p-values-and-what-now/">1</a>, <a href="http://www.tandfonline.com/doi/pdf/10.1080/01973533.2015.1012991">2</a>, <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Criticism">3</a></li>
</ul>
<p>To go from signficance to importance, we should:</p>
<ul>
<li>at least
check for the abscence of small effects shown above <em>and</em> the <em>rank</em> tests
shown below</li>
<li>at most ask a domain expert if the observed difference matters a hoot.</li>
</ul>
<p>For example, here are some
charts showing the effects on a population as we apply more and more of
some treatment. Note that the mean of the populations remains unchanged,
yet we might still endorse the treatment since it reduces the
uncertainty associated with each population.</p>
<p><img alt="img" src="https://raw.githubusercontent.com/txt/mase/master/img/index_customers_clip_image002.jpg" /></p>
<p>Note the large
overlap in the top two curves in those plots. When distributions exhibit
a very large overlap, it is very hard to determine if one is really
different to the other. So large variances can mean that even if the
means are <em>better</em>, we cannot really say that the values in one
distribution are usually better than the other.</p>
<p>In any case, what a signifcance test does is report how small
is the overlap between two distributions (and if it is very small,
then we say the differences are <em>statistically significant</em>.</p>
<h4 id="t-test-parametric-significance-test">T-test (parametric Significance Test)</h4>
<p>Assuming the populations are bell-shaped curve, when are two curves not significantly
different?</p>
<pre><code class="python">class Num:
  &quot;An Accumulator for numbers&quot;
  def __init__(i,inits=[]):
    i.n = i.m2 = i.mu = 0.0
    for x in inits: i.add(x)
  def s(i): return (i.m2/(i.n - 1))**0.5
  def add(i,x):
    i._median=None
    i.n   += 1
    delta  = x - i.mu
    i.mu  += delta*1.0/i.n
    i.m2  += delta*(x - i.mu)
  def tTestSame(i,j,conf=0.95):
    nom   = abs(i.mu - j.mu)
    s1,s2 = i.s(), j.s()
    denom = ((s1/i.n + s2/j.n)**0.5) if s1+s2 else 1
    df    = min(i.n - 1, j.n - 1)
    return  criticalValue(df, conf) &gt;= nom/denom
</code></pre>

<p>The above needs a magic threshold )(on the last line) for sayng enough is enough</p>
<pre><code class="python">def criticalValue(df,conf=0.95,
  xs= [          1,     2,     5,      10,    15,      20,    25,     30,       60,  100],
  ys= {0.9:  [ 3.078, 1.886, 1.476, 1.372, 1.341, 1.325, 1.316, 1.31,  1.296, 1.29],
       0.95: [ 6.314, 2.92,  2.015, 1.812, 1.753, 1.725, 1.708, 1.697, 1.671, 1.66],
       0.99: [31.821, 6.965, 3.365, 2.764, 2.602, 2.528, 2.485, 2.457, 2.39,  2.364]}):
  return interpolate(df, xs, ys[conf])

def interpolate(x,xs,ys):
  if x &lt;= xs[0] : return ys[0]
  if x &gt;= xs[-1]: return ys[-1]
  x0, y0 = xs[0], ys[0]
  for x1,y1 in zip(xs,ys):
    if x &lt; x0 or x &gt; xs[-1] or x0 &lt;= x &lt; x1:
      break
    x0, y0 = x1, y1
  gap = (x - x0)/(x1 - x0)
  return y0 + gap*(y1 - y0)
</code></pre>

<p>Many distributions are not normal so I use this <code>tTestSame</code> as a heuristic for
speed criticl calcs. E.g. in the inner inner loop of some search where i need a
quick opinion, is "this" the same as "that".</p>
<p>But when assessing experimental results after all the algorithms have terminated, I use a much
safer, but somewhat slower, procedure:</p>
<h4 id="bootstrap-non-parametric-significance-test">Bootstrap (Non-parametric Significance Test)</h4>
<p>The world is not normal:</p>
<p>Here are  50 different SQL queries and the distribution of times
CPU is waiting on hard drive i/o:</p>
<p><img src="https://raw.githubusercontent.com/txt/ase16/master/img/notnorm8.png"></p>
<p>So, when the world is a funny shape, what to do?</p>
<p>The following <em>bootstrap</em> method was introduced in
1979 by Bradley Efron at Stanford University. It
was inspired by earlier work on the
jackknife.
Improved estimates of the variance were <a href="http://goo.gl/14n8Wf" title="Bradley Efron and R.J. Tibshirani. An Introduction to the Bootstrap (Chapman &amp; Hall/CRC Monographs on Statistics &amp; Applied Probability), 1993">developed later</a>.</p>
<p>To check if two populations <em>(y0,z0)</em>
are different using the bootstrap, many times sample with replacement
from both to generate <em>(y1,z1), (y2,z2), (y3,z3)</em>.. etc.</p>
<pre><code class="python">def sampleWithReplacement(lst):
  &quot;returns a list same size as list&quot;
  def any(n)  : return random.uniform(0,n)
  def one(lst): return lst[ int(any(len(lst))) ]
  return [one(lst) for _ in lst]
</code></pre>

<p>Then, for all those samples,
 check if some <em>testStatistic</em> in the original pair
hold for all the other pairs. If it does more than (say) 99%
of the time, then we are 99% confident in that the
populations are the same.</p>
<p>In such a <em>bootstrap</em> hypothesis test, the <em>some property</em>
is the difference between the two populations, muted by the
joint standard deviation of the populations.</p>
<pre><code class="python">def testStatistic(y,z):
    &quot;&quot;&quot;Checks if two means are different, tempered
     by the sample size of 'y' and 'z'&quot;&quot;&quot;
    tmp1 = tmp2 = 0
    for y1 in y.all: tmp1 += (y1 - y.mu)**2
    for z1 in z.all: tmp2 += (z1 - z.mu)**2
    s1    = (float(tmp1)/(y.n - 1))**0.5
    s2    = (float(tmp2)/(z.n - 1))**0.5
    delta = z.mu - y.mu
    if s1+s2:
      delta =  delta/((s1/y.n + s2/z.n)**0.5)
    return delta
</code></pre>

<p>The rest is just details:</p>
<ul>
<li>Efron advises
  to make the mean of the populations the same (see
  the <em>yhat,zhat</em> stuff shown below).</li>
<li>The class <em>total</em> is a just a quick and dirty accumulation class.</li>
<li>For more details see <a href="http://goo.gl/14n8Wf" title="Bradley Efron and R.J. Tibshirani. An Introduction to the Bootstrap (Chapman &amp; Hall/CRC Monographs on Statistics &amp; Applied Probability), 1993">the Efron text</a>.</li>
</ul>
<pre><code class="python">def bootstrap(y0,z0,conf=The.conf,b=The.b):
  &quot;&quot;&quot;The bootstrap hypothesis test from
     p220 to 223 of Efron's book 'An
    introduction to the boostrap.&quot;&quot;&quot;
  class total():
    &quot;quick and dirty data collector&quot;
    def __init__(i,some=[]):
      i.sum = i.n = i.mu = 0 ; i.all=[]
      for one in some: i.put(one)
    def put(i,x):
      i.all.append(x);
      i.sum +=x; i.n += 1; i.mu = float(i.sum)/i.n
    def __add__(i1,i2): return total(i1.all + i2.all)
  y, z   = total(y0), total(z0)
  x      = y + z
  tobs   = testStatistic(y,z)
  yhat   = [y1 - y.mu + x.mu for y1 in y.all]
  zhat   = [z1 - z.mu + x.mu for z1 in z.all]
  bigger = 0.0
  for i in range(b):
    if testStatistic(total(sampleWithReplacement(yhat)),
                     total(sampleWithReplacement(zhat))) &gt; tobs:
      bigger += 1
  return bigger / b &lt; conf
</code></pre>

<p>Warning- bootstrap can be slow.
As to how many bootstraps are enough, that depends on the data. There are
results saying 200 to 400 are enough but, since I am  suspicious man, I run it for 1000.
Which means the runtimes associated with bootstrapping is a significant issue.
To reduce that runtime, I avoid things like an all-pairs comparison of all treatments
(see below: Scott-knott).  Also, BEFORE I do the boostrap, I first run
the effect size test (and only go to bootstrapping in effect size passes:</p>
<pre><code class="python">def different(l1,l2):
  #return bootstrap(l1,l2) and a12(l2,l1)
  return not a12(l2,l1) and bootstrap(l1,l2)

</code></pre>

<h4 id="scott-knott-so-how-to-rank">Scott-Knott So, How to Rank?</h4>
<p>The following code, which you can use verbatim from <code>stats.py</code> does the following:
+ All treatments are recursively bi-clustered into <em>ranks</em>.
+ At each level, the treatments are split at the point where the expected
  values of the treatments after the split is most different to before,
+ Before recursing downwards, Bootstrap+A12 is called to check that
  that the two splits are actually different (if not: halt!)</p>
<p>In practice,
+ Dozens of treatments end up generating just a handful of ranks.
+ The numbers of calls to the hypothesis tests are minimized:
    + Treatments are sorted by their median value.
    + Treatments are divided into two groups such that the
      expected value of the mean values <em>after</em> the split is minimized;
    + Hypothesis tests are called to test if the two groups are truly difference.
          + All hypothesis tests are non-parametric and include (1) effect size tests
            and (2) tests for statistically significant numbers;
          + Slow bootstraps are executed  if the faster <em>A12</em> tests are passed;</p>
<p>In practice, this means that the hypothesis tests (with confidence of say, 95%)
are called on only a logarithmic number of times. So...</p>
<ul>
<li>With this method, 16 treatments can be studied using less than <em>&sum;<sub>1,2,4,8,16</sub>log<sub>2</sub>i =15</em> hypothesis tests  and confidence <em>0.99<sup>15</sup>=0.86</em>.</li>
<li>But if did this with the 120 all-pairs comparisons of the 16 treatments, we would have total confidence <em>0.99<sup>120</sup>=0.30</em>.</li>
</ul>
<p>For examples on using this code, run <code>cat statX.txt | python stats.py</code>.</p>
<p>The results of a Scott-Knott+Bootstrap+A12 is a very simple
presentation of a very complex set of results:
img/notnorm8.png</p>
<p><a href="https://raw.githubusercontent.com/txt/ase16/master/img/results1.png"><img width=600 src="https://raw.githubusercontent.com/txt/ase16/master/img/results1.png"></a><br></p>
<p><a href="https://raw.githubusercontent.com/txt/ase16/master/img/result2.png"><img width=600 src="https://raw.githubusercontent.com/txt/ase16/master/img/result2.png"></a></p></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
